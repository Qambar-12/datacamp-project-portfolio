{"cells":[{"source":"# What's in an Avocado Toast: A Supply Chain Analysis\n\n![](avocado_wallpaper.jpeg)\n\nYou find yourself in London, crafting a delectable avocado toast, a dish that has risen dramatically in popularity on breakfast menus since the 2010s. This straightforward recipe requires just five ingredients: a ripe avocado, half a lemon, a generous pinch of salt flakes, two slices of sourdough bread, and a good drizzle of extra virgin olive oil. Most of these ingredients are now staples in grocery stores, and as you will find with this project, that is no small feat!\n\nIn this project, you'll conduct a supply chain analysis of three ingredients used in avocado toast using the Open Food Facts database. This database contains extensive, openly-sourced information on various foods, including their origins. Through this analysis, you will gain an in-depth understanding of the complex supply chain involved in producing a single dish.\n\nThree pairs of files are provided in the data folder:\n- A CSV file for each ingredient, such as `avocado.csv`, with data about each food item and countries of origin.\n- A TXT file for each ingredient, such as `relevant_avocado_categories`, containing only the category tags of interest for that food.\n\nHere are some other key points about these files:\n- Some of the rows of data in each of the three CSV files do not contain relevant data for your investigation. In each dataset, you will need to filter out rows with irrelevant data, based on values in the `categories_tags` column. Examples of categories are fruits, vegetables, and fruit-based oils. Filter the DataFrame to include only rows where `categories_tags` contains one of the tags in the relevant categories for that ingredient.\n- Each row of data usually has multiple category tags in the `categories_tags` column.\nThere is a column in each CSV file called `origins_tags`, which contains strings for the country of origin of each item.\n\nAfter completing this project, you'll be armed with a list of ingredients and their countries of origin and be well-positioned to launch into other analyses that explore how long, on average, these ingredients spend at sea.\n\n[Open Food Facts database](https://world.openfoodfacts.org/)","metadata":{},"id":"32ec92a0-c21a-45b8-ac63-9f9c698a1291","cell_type":"markdown"},{"source":"import pandas as pd","metadata":{"executionTime":49,"lastSuccessfullyExecutedCode":"import pandas as pd","executionCancelledAt":null,"lastExecutedAt":1742816703181,"lastExecutedByKernel":"9d2456c4-8f92-4919-abf5-23ebaaad58fc","lastScheduledRunId":null},"id":"339a6352-aed5-4b9e-a48f-1b91a7db9adb","cell_type":"code","execution_count":9,"outputs":[]},{"source":"## Read_and_Filter Data","metadata":{},"cell_type":"markdown","id":"dc071d90-a80c-41f7-b0bb-c200769abb2e"},{"source":"def read_and_filter_data(filename, relevant_categories):\n    #tab-delimited file\n  df = pd.read_csv('data/' + filename, sep='\\t')\n  \n  # Subset large DataFrame to include only relevant columns\n  subset_columns = [ 'code', 'lc', 'product_name_en', 'quantity', 'serving_size', 'packaging_tags', 'brands', 'brands_tags', 'categories_tags', 'labels_tags', 'countries', 'countries_tags', 'origins','origins_tags']\n  df = df[subset_columns]\n\n  # Split tags into lists\n  df['categories_list'] = df['categories_tags'].str.split(',')\n\n  # Drop rows with null categories data\n  df = df.dropna(subset = 'categories_list')\n\n  # Filter data for relevant categories\n  df = df[df['categories_list'].apply(lambda x: any([i for i in x if i in relevant_categories]))]\n    \n  # Filter data for the UK\n  df_uk = df[(df['countries']=='United Kingdom')]\n\n  # Find top origin country string with the highest count\n  top_origin_string = (df_uk['origins_tags'].value_counts().index[0])\n\n  # Clean up top origin country string\n  top_origin_country = top_origin_string.lstrip(\"en:\")\n  top_origin_country = top_origin_country.replace('-', ' ')\n\n  print(f'**{filename[:-4]} origins**','\\n', top_origin_country, '\\n')\n\n  print (\"Top origin country: \", top_origin_country)\n  print (\"\\n\")\n\n  # End of function - return top origin country for this ingredient\n  return top_origin_country\n","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1742816703233,"lastExecutedByKernel":"9d2456c4-8f92-4919-abf5-23ebaaad58fc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def read_and_filter_data(filename, relevant_categories):\n    #tab-delimited file\n  df = pd.read_csv('data/' + filename, sep='\\t')\n  \n  # Subset large DataFrame to include only relevant columns\n  subset_columns = [ 'code', 'lc', 'product_name_en', 'quantity', 'serving_size', 'packaging_tags', 'brands', 'brands_tags', 'categories_tags', 'labels_tags', 'countries', 'countries_tags', 'origins','origins_tags']\n  df = df[subset_columns]\n\n  # Split tags into lists\n  df['categories_list'] = df['categories_tags'].str.split(',')\n\n  # Drop rows with null categories data\n  df = df.dropna(subset = 'categories_list')\n\n  # Filter data for relevant categories\n  df = df[df['categories_list'].apply(lambda x: any([i for i in x if i in relevant_categories]))]\n    \n  # Filter data for the UK\n  df_uk = df[(df['countries']=='United Kingdom')]\n\n  # Find top origin country string with the highest count\n  top_origin_string = (df_uk['origins_tags'].value_counts().index[0])\n\n  # Clean up top origin country string\n  top_origin_country = top_origin_string.lstrip(\"en:\")\n  top_origin_country = top_origin_country.replace('-', ' ')\n\n  print(f'**{filename[:-4]} origins**','\\n', top_origin_country, '\\n')\n\n  print (\"Top origin country: \", top_origin_country)\n  print (\"\\n\")\n\n  # End of function - return top origin country for this ingredient\n  return top_origin_country\n","outputsMetadata":{"0":{"height":353,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"27311712-9fe4-41fb-aea8-837712a645fd","outputs":[],"execution_count":10},{"source":"## Avocado","metadata":{},"cell_type":"markdown","id":"a7e1c2f3-3078-4f9d-95c6-cf0814228dc0"},{"source":"# Gather relevant categories data for avocados\nwith open(\"data/relevant_avocado_categories.txt\", \"r\") as file:\n    relevant_avocado_categories = file.read().splitlines()\n    file.close()\ntop_avocado_origin = read_and_filter_data('avocado.csv',relevant_avocado_categories)    ","metadata":{"executionCancelledAt":null,"executionTime":64,"lastExecutedAt":1742816703297,"lastExecutedByKernel":"9d2456c4-8f92-4919-abf5-23ebaaad58fc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Gather relevant categories data for avocados\nwith open(\"data/relevant_avocado_categories.txt\", \"r\") as file:\n    relevant_avocado_categories = file.read().splitlines()\n    file.close()\ntop_avocado_origin = read_and_filter_data('avocado.csv',relevant_avocado_categories)    "},"cell_type":"code","id":"d0b2739f-0016-4526-9165-18cd7c00ad18","outputs":[{"output_type":"stream","name":"stdout","text":"**avocado origins** \n peru \n\nTop origin country:  peru\n\n\n"}],"execution_count":11},{"source":"## Olive oil","metadata":{},"cell_type":"markdown","id":"5f6c66c4-df89-489b-8cb2-3db1a1a2930b"},{"source":"with open(\"data/relevant_olive_oil_categories.txt\", \"r\") as file:\n    relevant_olive_oil_categories = file.read().splitlines()\n    file.close()\n\ntop_olive_oil_origin = read_and_filter_data('olive_oil.csv',relevant_olive_oil_categories)","metadata":{"executionCancelledAt":null,"executionTime":403,"lastExecutedAt":1742816703700,"lastExecutedByKernel":"9d2456c4-8f92-4919-abf5-23ebaaad58fc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"with open(\"data/relevant_olive_oil_categories.txt\", \"r\") as file:\n    relevant_olive_oil_categories = file.read().splitlines()\n    file.close()\n\ntop_olive_oil_origin = read_and_filter_data('olive_oil.csv',relevant_olive_oil_categories)"},"cell_type":"code","id":"5b52812c-5202-4c0d-b96b-5b31ae2fadf5","outputs":[{"output_type":"stream","name":"stdout","text":"**olive_oil origins** \n greece \n\nTop origin country:  greece\n\n\n"}],"execution_count":12},{"source":"## Sourdough","metadata":{},"cell_type":"markdown","id":"8eabe0d6-22c4-4fe4-8e42-82fe1dd0505a"},{"source":"with open(\"data/relevant_sourdough_categories.txt\", \"r\") as file:\n    relevant_sourdough_categories = file.read().splitlines()\n    file.close()\n\ntop_sourdough_origin = read_and_filter_data('sourdough.csv',relevant_sourdough_categories)","metadata":{"executionCancelledAt":null,"executionTime":63,"lastExecutedAt":1742816703763,"lastExecutedByKernel":"9d2456c4-8f92-4919-abf5-23ebaaad58fc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"with open(\"data/relevant_sourdough_categories.txt\", \"r\") as file:\n    relevant_sourdough_categories = file.read().splitlines()\n    file.close()\n\ntop_sourdough_origin = read_and_filter_data('sourdough.csv',relevant_sourdough_categories)"},"cell_type":"code","id":"b1d5d306-7243-4ac8-82c9-6ce76ee97bcf","outputs":[{"output_type":"stream","name":"stdout","text":"**sourdough origins** \n united kingdom \n\nTop origin country:  united kingdom\n\n\n"}],"execution_count":13}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}