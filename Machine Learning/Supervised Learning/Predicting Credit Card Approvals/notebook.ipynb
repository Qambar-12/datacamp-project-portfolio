{"cells":[{"source":"![Credit card being held in hand](credit_card.jpg)\n\nCommercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n\n### The Data\n\nThe data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value.","metadata":{},"id":"35aebf2e-0635-4fef-bc9a-877b6a20fb13","cell_type":"markdown"},{"source":"## Exploratory Data Analysis","metadata":{},"cell_type":"markdown","id":"f6b56567-d377-45e0-adb7-b25359281a86"},{"source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split , KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \n#to familiarize with dataset \nprint(cc_apps.head())\n#to check for any missing values that can be dropped or imputed\nfor col in cc_apps.columns:\n    print(cc_apps[col].unique())\n","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1742297115257,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split , KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \n#to familiarize with dataset \nprint(cc_apps.head())\n#to check for any missing values that can be dropped or imputed\nfor col in cc_apps.columns:\n    print(cc_apps[col].unique())\n","outputsMetadata":{"0":{"height":378,"type":"stream"}},"lastExecutedByKernel":"3a796919-c4df-4a33-a1a3-aa8b809914d2","visualizeDataframe":false,"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"6e86b1e8-a3fa-4b09-982f-795f218bd1a6","cell_type":"code","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +\n['b' 'a' '?']\n['30.83' '58.67' '24.50' '27.83' '20.17' '32.08' '33.17' '22.92' '54.42'\n '42.50' '22.08' '29.92' '38.25' '48.08' '45.83' '36.67' '28.25' '23.25'\n '21.83' '19.17' '25.00' '47.75' '27.42' '41.17' '15.83' '47.00' '56.58'\n '57.42' '42.08' '29.25' '42.00' '49.50' '36.75' '22.58' '27.25' '23.00'\n '27.75' '54.58' '34.17' '28.92' '29.67' '39.58' '56.42' '54.33' '41.00'\n '31.92' '41.50' '23.92' '25.75' '26.00' '37.42' '34.92' '34.25' '23.33'\n '23.17' '44.33' '35.17' '43.25' '56.75' '31.67' '23.42' '20.42' '26.67'\n '36.00' '25.50' '19.42' '32.33' '34.83' '38.58' '44.25' '44.83' '20.67'\n '34.08' '21.67' '21.50' '49.58' '27.67' '39.83' '?' '37.17' '25.67'\n '34.00' '49.00' '62.50' '31.42' '52.33' '28.75' '28.58' '22.50' '28.50'\n '37.50' '35.25' '18.67' '54.83' '40.92' '19.75' '29.17' '24.58' '33.75'\n '25.42' '37.75' '52.50' '57.83' '20.75' '39.92' '24.75' '44.17' '23.50'\n '47.67' '22.75' '34.42' '28.42' '67.75' '47.42' '36.25' '32.67' '48.58'\n '33.58' '18.83' '26.92' '31.25' '56.50' '43.00' '22.33' '32.83' '40.33'\n '30.50' '52.83' '46.67' '58.33' '37.33' '23.08' '32.75' '68.67' '28.00'\n '44.00' '25.08' '32.00' '60.58' '40.83' '19.33' '41.33' '56.00' '49.83'\n '22.67' '27.00' '26.08' '18.42' '21.25' '57.08' '22.42' '48.75' '40.00'\n '40.58' '28.67' '33.08' '21.33' '41.75' '34.50' '48.17' '27.58' '24.08'\n '24.83' '36.33' '35.42' '71.58' '39.50' '39.33' '24.33' '60.08' '55.92'\n '53.92' '18.92' '50.08' '65.42' '17.58' '18.08' '19.67' '25.17' '33.50'\n '58.42' '26.17' '42.83' '38.17' '20.50' '48.25' '28.33' '18.75' '18.50'\n '45.00' '40.25' '41.42' '17.83' '18.17' '20.00' '52.17' '50.75' '17.08'\n '18.33' '59.67' '18.00' '37.58' '30.67' '18.58' '16.25' '21.17' '17.67'\n '16.50' '29.50' '21.75' '18.25' '35.75' '16.08' '69.17' '32.92' '16.33'\n '22.17' '57.58' '15.92' '31.75' '19.00' '17.50' '33.67' '30.17' '33.25'\n '25.25' '34.75' '47.33' '39.08' '42.75' '38.92' '62.75' '32.25' '26.75'\n '63.33' '30.75' '16.00' '19.50' '32.42' '30.25' '26.83' '16.92' '24.42'\n '39.42' '23.58' '21.42' '33.00' '26.33' '26.25' '28.17' '20.83' '43.17'\n '56.83' '15.17' '29.83' '31.00' '51.92' '69.50' '19.58' '22.25' '38.42'\n '26.58' '35.00' '29.42' '49.17' '51.83' '58.58' '53.33' '27.17' '25.92'\n '30.58' '17.25' '27.33' '36.50' '29.75' '52.42' '36.17' '34.58' '21.92'\n '36.58' '31.08' '30.42' '21.08' '17.42' '39.17' '26.50' '17.33' '23.75'\n '34.67' '74.83' '45.33' '47.25' '24.17' '39.25' '39.00' '64.08' '31.33'\n '21.00' '13.75' '46.00' '20.25' '60.92' '30.00' '22.83' '45.17' '41.58'\n '55.75' '25.33' '31.83' '33.92' '24.92' '80.25' '30.08' '48.33' '76.75'\n '51.33' '41.92' '29.58' '32.17' '51.42' '42.17' '43.08' '59.50' '65.17'\n '20.33' '48.50' '28.08' '73.42' '51.58' '38.67' '46.08' '20.08' '42.25'\n '16.17' '47.83' '22.00' '38.33' '25.58' '21.58' '36.08' '38.75' '35.58'\n '31.58' '15.75' '17.92' '30.33' '47.17' '25.83' '50.25' '36.42']\n[ 0.     4.46   0.5    1.54   5.625  4.     1.04  11.585  4.915  0.83\n  1.835  6.     6.04  10.5    4.415  0.875  5.875  0.25   8.585 11.25\n  1.     8.    14.5    6.5    0.585 13.    18.5    8.5   14.79   9.79\n  7.585  5.125 10.75   1.5    1.585 11.75   9.415  9.17  15.     1.415\n 13.915 28.     6.75   2.04   0.665  2.5    3.    11.625  4.5   12.25\n 16.165  0.79   0.835  4.25   0.375 25.125  7.5    5.     7.     5.29\n  1.165  9.75  19.     3.5    0.625  2.21  12.75  15.5    1.375  3.54\n 11.     1.75  16.5   12.     2.25   0.75  12.5    1.25   1.125  7.04\n 10.335  6.21   6.665  9.     5.5    0.54   2.75   9.5   13.5    3.75\n 16.     0.29   1.665  7.54   0.46  10.    11.5    3.04   2.     0.08\n  1.71   3.25   2.54  13.585  8.665  9.25   8.17   2.335 19.5    5.665\n  4.625  0.205  0.96   4.04   5.04   3.165  7.625 10.04  10.25   2.125\n  9.335  6.625  2.71   9.625 12.54   9.54   8.46  13.75  21.    10.125\n 25.085  0.21  21.5   11.125 11.045  1.335  0.085  1.21   0.165  5.71\n  5.415 12.625  0.58   0.415  2.415  0.335  3.125 12.125  2.875 13.665\n 26.335 10.29   1.29  22.     0.125  1.085  4.085  4.71   6.165  4.585\n 11.46  14.585  0.17   1.625  2.085  5.085  8.125  2.835  1.79   0.705\n  2.165  2.29  18.125  3.085 11.665  4.125  1.08  13.335 11.835  4.79\n  9.96   7.08  25.21   0.67   3.79  22.29   3.335  0.42   1.46   0.04\n 12.33  12.335  0.915 14.    17.75  20.     5.25   4.165 10.915  4.75\n 10.415  7.835  0.71   2.46   9.585  3.625  2.665  5.835 12.835 10.665\n  7.25  10.21   3.29  10.085  3.375]\n['u' 'y' '?' 'l']\n['g' 'p' '?' 'gg']\n['w' 'q' 'm' 'r' 'cc' 'k' 'c' 'd' 'x' 'i' 'e' 'aa' 'ff' 'j' '?']\n['v' 'h' 'bb' 'ff' 'j' 'z' '?' 'o' 'dd' 'n']\n[ 1.25   3.04   1.5    3.75   1.71   2.5    6.5    0.04   3.96   3.165\n  2.165  4.335  1.     5.     0.25   0.96   3.17   0.665  0.75   0.835\n  7.875  3.085  0.5    5.165 15.     7.     5.04   7.96   7.585  0.415\n  2.     1.835 14.415  4.5    5.335  8.625 28.5    2.625  0.125  6.04\n  3.5    0.165  0.875  1.75   0.     7.415  0.085  5.75   6.     3.\n  1.585  4.29   1.54   1.46   1.625 12.5   13.5   10.75   0.375  0.585\n  0.455  4.     8.5    9.46   2.25  10.     0.795  1.375  1.29  11.5\n  6.29  14.     0.335  1.21   7.375  7.5    3.25  13.     5.5    4.25\n  0.625  5.085  2.75   2.375  8.     1.085  2.54   4.165  1.665 11.\n  9.     1.335  1.415  1.96   2.585  5.125 15.5    0.71   5.665 18.\n  5.25   8.665  2.29  20.     2.46  13.875  2.085  4.58   2.71   2.04\n  0.29   4.75   0.46   0.21   0.54   3.335  2.335  1.165  2.415  2.79\n  4.625  1.04   6.75   1.875 16.    12.75   5.375  2.125 17.5    3.125\n  0.79   8.29 ]\n['t' 'f']\n['t' 'f']\n[ 1  6  0  5  7 10  3 17  2  9  8 15 11 12 40 23  4 20 67 14 16 13 19]\n['g' 's' 'p']\n[     0    560    824      3  31285   1349    314   1442    200   2690\n    245   1208   1260     11  10000   5000   4000     35    713    551\n    500    300    221   2283    100     15    284   1236   5800    730\n    400  50000    456  15108   2954      2     20     27    225      1\n     38      5    130    147    210  11202   1332     50    258    567\n   1000   2510    809    610    150  51100    367    600    247    375\n    278    827   2072    582   2300   3065   2200      6   1602   2184\n   3376   2000   7544  10561    837  11177    639   2028   1065    540\n    158  15000   3000   3257   1655   1430      7    790    396    678\n   1187   6590    168   1270   1210    742   8851   7059   1704    857\n   6700   2503   9800    196     14  26726  18027     99    444   1200\n   2010     13    120     32    722     40    484    204     98   5552\n    105   2803    126      4     21    173     10     25     42 100000\n    113      8     44   2732    179     16   1062    251    228     67\n     12    122   4208   1300    112   1110   1004    286   4500   1212\n    195     87     17    184    140     18    146     22     55     70\n     60   1058    769   5200     19    316    350   3552    687   1950\n     53     41     33     80    351   2100    475    892   4607   2206\n   5860     28   1391   2279    591    960    690    234    800    990\n   2197     90    340    347    327   4071    109   1249    134   1344\n    321    948   2079   2384    458   5298    162   1583     58     59\n   1400   1465   8000   4700   1097   3290  13212   5777   5124     23\n   4159    918    768    283    108      9     68    587    141    501\n    160    390    154    117    246    237    364    537    394    750]\n['+' '-']\n"}]},{"source":"## Preprocessing Data","metadata":{},"cell_type":"markdown","id":"529646c1-c3c1-45dd-a644-101714e9c25d"},{"source":"# Replace the '?'s with NaN in dataset\ncc_apps_nans_replaced = cc_apps.replace(\"?\", np.NaN)\n# Create a copy of the NaN replacement DataFrame\ncc_apps_imputed = cc_apps_nans_replaced.copy()\n# Iterate over each column of cc_apps_nans_replaced and impute the most frequent value for object data types and the mean for numeric data types\nfor col in cc_apps_imputed.columns:\n    # Check if the column is of object type (categorical)\n    if cc_apps_imputed[col].dtypes == \"object\":\n        # Impute with the most frequent value i.e the mode\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(\n            cc_apps_imputed[col].mode()\n        )\n    else:\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].mean())\n# Dummify the categorical features (because scikit-learn takes only numeric values)\n#drop_first is set to true to avoid data_duplication\ncc_apps_encoded = pd.get_dummies(cc_apps_imputed, drop_first=True)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1742297115309,"lastExecutedByKernel":"3a796919-c4df-4a33-a1a3-aa8b809914d2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Replace the '?'s with NaN in dataset\ncc_apps_nans_replaced = cc_apps.replace(\"?\", np.NaN)\n# Create a copy of the NaN replacement DataFrame\ncc_apps_imputed = cc_apps_nans_replaced.copy()\n# Iterate over each column of cc_apps_nans_replaced and impute the most frequent value for object data types and the mean for numeric data types\nfor col in cc_apps_imputed.columns:\n    # Check if the column is of object type (categorical)\n    if cc_apps_imputed[col].dtypes == \"object\":\n        # Impute with the most frequent value i.e the mode\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(\n            cc_apps_imputed[col].mode()\n        )\n    else:\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].mean())\n# Dummify the categorical features (because scikit-learn takes only numeric values)\n#drop_first is set to true to avoid data_duplication\ncc_apps_encoded = pd.get_dummies(cc_apps_imputed, drop_first=True)"},"cell_type":"code","id":"8ace7a18-44d0-4a30-82dc-436309e377a9","outputs":[],"execution_count":15},{"source":"## Subsetting ,Splitting and Scaling","metadata":{},"cell_type":"markdown","id":"60b1a59d-3298-40b3-812d-81556dcb9327"},{"source":"# Extracting features\nX = cc_apps_encoded.iloc[:, :-1].values\n# Extracting the last column as target variable \ny = cc_apps_encoded.iloc[:, [-1]].values\n#train_test split\nX_train , X_test ,y_train , y_test = train_test_split(X,y,test_size=0.25,random_state=12,stratify=y)\n#scaling data \nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1742297115357,"lastExecutedByKernel":"3a796919-c4df-4a33-a1a3-aa8b809914d2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Extracting features\nX = cc_apps_encoded.iloc[:, :-1].values\n# Extracting the last column as target variable \ny = cc_apps_encoded.iloc[:, [-1]].values\n#train_test split\nX_train , X_test ,y_train , y_test = train_test_split(X,y,test_size=0.25,random_state=12,stratify=y)\n#scaling data \nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","outputsMetadata":{"0":{"height":378,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"6e541ef6-67f1-43bc-8886-3b4749e09538","outputs":[],"execution_count":16},{"source":"## Train Model","metadata":{},"cell_type":"markdown","id":"94807510-9b4e-4fe7-a93e-caebfbb7c8fa"},{"source":"#Instantiate the model\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train_scaled,y_train)\n#predictions from training set\ny_train_pred = log_reg.predict(X_train_scaled)\n# Print the confusion matrix of the logreg model\nprint(confusion_matrix(y_train, y_train_pred))\n","metadata":{"executionCancelledAt":null,"executionTime":180,"lastExecutedAt":1742297115537,"lastExecutedByKernel":"3a796919-c4df-4a33-a1a3-aa8b809914d2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Instantiate the model\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train_scaled,y_train)\n#predictions from training set\ny_train_pred = log_reg.predict(X_train_scaled)\n# Print the confusion matrix of the logreg model\nprint(confusion_matrix(y_train, y_train_pred))\n","outputsMetadata":{"0":{"height":59,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"aa091278-1a22-4411-bca5-b7cd71affccd","outputs":[{"output_type":"stream","name":"stdout","text":"[[226   4]\n [  5 282]]\n"}],"execution_count":17},{"source":"## Hyperparameter tuning (GridSearchCV ---> CrossValidation)","metadata":{},"cell_type":"markdown","id":"3fa1b0f0-c171-4d15-b133-6d650739d113"},{"source":"#parameter grid (dictionary)\n#2 hyperparameters i.e tolerance and max_iterations\n#iterative optimization parameters (gradient descent)\n#tolerance is difference between two consecutive values of cost function if it is less than tol parameter the iterative procedure stops\n#total fits = p hyperparametes * q values * k foldsCV\nparam_grid = {\"tol\":[0.01,0.001,0.0001]  , \"max_iter\":[100,150,200]}\nkf = KFold(n_splits = 5,shuffle = True,random_state=12)\n# Instantiate GridSearchCV with the required parameters\ngrid_cv = GridSearchCV(estimator = log_reg, param_grid=param_grid , cv=kf)\ngrid_cv_res = grid_cv.fit(X_train_scaled,y_train)","metadata":{"executionCancelledAt":null,"executionTime":10496,"lastExecutedAt":1742297126033,"lastExecutedByKernel":"3a796919-c4df-4a33-a1a3-aa8b809914d2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#parameter grid (dictionary)\n#2 hyperparameters i.e tolerance and max_iterations\n#iterative optimization parameters (gradient descent)\n#tolerance is difference between two consecutive values of cost function if it is less than tol parameter the iterative procedure stops\n#total fits = p hyperparametes * q values * k foldsCV\nparam_grid = {\"tol\":[0.01,0.001,0.0001]  , \"max_iter\":[100,150,200]}\nkf = KFold(n_splits = 5,shuffle = True,random_state=12)\n# Instantiate GridSearchCV with the required parameters\ngrid_cv = GridSearchCV(estimator = log_reg, param_grid=param_grid , cv=kf)\ngrid_cv_res = grid_cv.fit(X_train_scaled,y_train)"},"cell_type":"code","id":"add4c09f-44f6-4dbe-af72-f8a5563cee69","outputs":[],"execution_count":18},{"source":"## Best scoring model","metadata":{},"cell_type":"markdown","id":"16034c11-ca4a-4bd7-a9de-9f6d0194ce6e"},{"source":"# Summarize results for training set \nbest_train_score, best_train_params = grid_cv_res.best_score_, grid_cv_res.best_params_\nprint(\"Best: %f using %s\" % (best_train_score, best_train_params))\n#Extracting best model and evaluate it on test set\nbest_model = grid_cv_res.best_estimator_\nbest_score = best_model.score(X_test_scaled,y_test)\nprint(best_score)","metadata":{"executionCancelledAt":null,"executionTime":107,"lastExecutedAt":1742297126142,"lastExecutedByKernel":"3a796919-c4df-4a33-a1a3-aa8b809914d2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Summarize results for training set \nbest_train_score, best_train_params = grid_cv_res.best_score_, grid_cv_res.best_params_\nprint(\"Best: %f using %s\" % (best_train_score, best_train_params))\n#Extracting best model and evaluate it on test set\nbest_model = grid_cv_res.best_estimator_\nbest_score = best_model.score(X_test_scaled,y_test)\nprint(best_score)","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"7262e5a3-b6ce-468d-aef0-d0ddfeb74d20","outputs":[{"output_type":"stream","name":"stdout","text":"Best: 0.779388 using {'max_iter': 100, 'tol': 0.01}\n0.791907514450867\n"}],"execution_count":19}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}